{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from lib.thop.profile import register_hooks\n",
    "import torch\n",
    "from lib.utils import AverageMeter, accuracy, prGreen,prRed\n",
    "import numpy as np\n",
    "import time\n",
    "import copy \n",
    "from lib.data import get_split_dataset\n",
    "\n",
    "class FM_reconstruct:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.compressed = model\n",
    "        self.repair_points = 3\n",
    "        self._init_data()\n",
    "        self._build_index()\n",
    "        self._extract_layer_information()\n",
    "        self._collect_XY()\n",
    "\n",
    "    \n",
    "    def _init_data(self):\n",
    "        # valset picking:\n",
    "        # for CIFAR, split 5k for val\n",
    "        # for ImageNet, split 3k for val\n",
    "        val_size = 5000 if 'cifar' in data_type else 3000\n",
    "        self.train_loader, self.val_loader, n_class = get_split_dataset(data_type, batch_size,\n",
    "                                                                        n_data_worker, val_size,\n",
    "                                                                        data_root,\n",
    "                                                                        shuffle=False)  # same sampling\n",
    "\n",
    "    def _add_hook_and_collect(self,model: nn.Module, inputs, custom_ops=None, verbose=True):\n",
    "        handler_collection = {}\n",
    "        types_collection = set()\n",
    "        if custom_ops is None:\n",
    "            custom_ops = {}\n",
    "\n",
    "        def add_hooks(m: nn.Module):\n",
    "\n",
    "            m_type = type(m)\n",
    "\n",
    "            fn = None\n",
    "            if m_type in custom_ops:  # if defined both op maps, use custom_ops to overwrite.\n",
    "                fn = custom_ops[m_type]\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    print(\"[INFO] Customize rule %s() %s.\" % (fn.__qualname__, m_type))\n",
    "            elif m_type in register_hooks:\n",
    "                fn = register_hooks[m_type]\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    print(\"[INFO] Register %s() for %s.\" % (fn.__qualname__, m_type))\n",
    "            else:\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    prRed(\"[WARN] Cannot find rule for %s. Treat it as zero Macs and zero Params.\" % m_type)\n",
    "\n",
    "            \n",
    "            def count_parameters(m, x, y):\n",
    "                total_params = 0\n",
    "                for p in m.parameters():\n",
    "                    total_params += torch.DoubleTensor([p.numel()])\n",
    "                m.total_params[0] = total_params\n",
    "            \n",
    "            handler_collection_xy = {}\n",
    "            if fn is not None: \n",
    "                m.register_buffer('total_ops', torch.zeros(1, dtype=torch.float64))\n",
    "                m.register_buffer('total_params', torch.zeros(1, dtype=torch.float64))\n",
    "                \n",
    "                handler_collection[m] = (m.register_forward_hook(fn), m.register_forward_hook(count_parameters))\n",
    "            types_collection.add(m_type)\n",
    "\n",
    "        prev_training_status = model.training\n",
    "\n",
    "        model.eval()\n",
    "        model.apply(add_hooks)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model(*inputs)\n",
    "\n",
    "        # collecting flops and params\n",
    "        for i,m in enumerate(self.model.modules()):\n",
    "            if i in self.all_idx:\n",
    "                self.params_dict[i] = m.total_params.item()\n",
    "                self.flops_dict[i] = m.total_ops.item()\n",
    "                self.params_list.append(m.total_params.item())\n",
    "                self.flops_list.append(m.total_ops.item())\n",
    "\n",
    "        model.train(prev_training_status)\n",
    "        for m, (op_handler, params_handler) in handler_collection.items():\n",
    "            op_handler.remove()\n",
    "            params_handler.remove()\n",
    "            m._buffers.pop(\"total_ops\")\n",
    "            m._buffers.pop(\"total_params\")\n",
    "        \n",
    "\n",
    "    def _flops_preprocessed(self):\n",
    "        self.conv_related_flops = {}\n",
    "        for idx,i in enumerate(self.prunable_idx):\n",
    "            flops = 0\n",
    "            if idx == 0:\n",
    "                pass\n",
    "            else:\n",
    "                j = i - 1\n",
    "                while self.layer_type_dict[j] != nn.Conv2d:\n",
    "                    flops+= self.flops_dict[j]\n",
    "                    j-=1\n",
    "            self.conv_related_flops[i] = flops\n",
    "\n",
    "    def _extract_layer_information(self):\n",
    "\n",
    "        self.layer_info_dict = dict()\n",
    "        self.flops_dict = {}\n",
    "        self.params_dict = {}\n",
    "        self.flops_list = []\n",
    "        self.params_list = []\n",
    "\n",
    "        print('=> Extracting information...')\n",
    "        input = torch.randn(1, 3, 32, 32).cuda()\n",
    "        self._add_hook_and_collect(self.model,(input, ))\n",
    "\n",
    "\n",
    "        self._flops_preprocessed()\n",
    "    def _build_index(self):\n",
    "        self.prunable_idx = []\n",
    "        self.prunable_ops = []\n",
    "        self.layer_type_dict = {}\n",
    "        self.org_channels = []\n",
    "        self.conv_buffer_dict = {} # layer after the conv\n",
    "        self.all_idx = []\n",
    "        self.buffer_conv_map = {}\n",
    "        self.strategy_dict = {}\n",
    "        self.op2idx = {}\n",
    "        self.idx2op = {}\n",
    "        self.org_Outchannels = []\n",
    "        self.org_Inchannels = []\n",
    "\n",
    "        modules = list(self.model.modules())\n",
    "        self.m_list = list(self.model.modules())\n",
    "        for i,mi in enumerate(modules):\n",
    "            if type(mi) not in list(register_hooks):\n",
    "                continue\n",
    "            self.all_idx.append(i)\n",
    "            if type(mi) == nn.Conv2d:\n",
    "                self.prunable_ops.append(mi)\n",
    "                self.prunable_idx.append(i)\n",
    "                self.op2idx[mi] = i\n",
    "                self.idx2op[i] = mi\n",
    "                self.org_Outchannels.append(mi.out_channels)\n",
    "                self.org_Inchannels.append(mi.in_channels)\n",
    "                self.strategy_dict[i] = 1.0\n",
    "            self.layer_type_dict[i] = type(mi)\n",
    "        self.identity_strategy_dict = copy.deepcopy(self.strategy_dict)\n",
    "        \n",
    "\n",
    "    def validate(self, verbose=True):\n",
    "        '''\n",
    "        Validate the performance on validation set\n",
    "        :param val_loader:\n",
    "        :param model:\n",
    "        :param verbose:\n",
    "        :return:\n",
    "        '''\n",
    "        val_loader = self.val_loader\n",
    "        model = self.compressed\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "        end = time.time()\n",
    "\n",
    "        t1 = time.time()\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(val_loader):\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input_var = torch.autograd.Variable(input).cuda()\n",
    "                target_var = torch.autograd.Variable(target).cuda()\n",
    "\n",
    "                # compute output\n",
    "                output = model(input_var)\n",
    "                loss = criterion(output, target_var)\n",
    "\n",
    "                # measure accuracy and record loss\n",
    "                prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "                losses.update(loss.item(), input.size(0))\n",
    "                top1.update(prec1.item(), input.size(0))\n",
    "                top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "                # measure elapsed time\n",
    "                batch_time.update(time.time() - end)\n",
    "                end = time.time()\n",
    "        t2 = time.time()\n",
    "        if verbose:\n",
    "            print('* Test loss: %.3f    top1: %.3f    top5: %.3f    time: %.3f' %\n",
    "                  (losses.avg, top1.avg, top5.avg, t2 - t1))\n",
    "        # if acc_metric == 'acc1':\n",
    "        #     return top1.avg\n",
    "        # elif acc_metric == 'acc5':\n",
    "        #     return top5.avg\n",
    "        # else:\n",
    "        #     raise NotImplementedError\n",
    "        \n",
    "    def compress(self,strategy):\n",
    "        def preprocess_get_mask(select,method = 'l1'):\n",
    "            mask = []\n",
    "            for i,a in enumerate(select):\n",
    "                c = self.org_Inchannels[i]\n",
    "                d = int(c * a)\n",
    "                mask_ = np.zeros(c,bool)\n",
    "                weight = self.prunable_ops[i].weight.data.cpu().numpy()\n",
    "                if method == 'l1':\n",
    "                    importance = np.abs(weight).sum((0, 2, 3))\n",
    "                    sorted_idx = np.argsort(-importance)  # sum magnitude along C_in, sort descend\n",
    "                    preserve_idx = sorted_idx[:d]  # to preserve index\n",
    "                    mask_[preserve_idx] = True\n",
    "                mask.append(mask_)\n",
    "            return mask\n",
    "        mask = preprocess_get_mask(strategy)\n",
    "        self.compressed = MaskVGG_IN('vgg16',strategy).cuda()\n",
    "        self.pruned_model(self.model,self.compressed,mask)\n",
    "        return self.compressed\n",
    "\n",
    "    def pruned_model(self,origin_model,pruned_model,all_mask):\n",
    "        m_list = list(origin_model.modules())\n",
    "        mp_list = list(pruned_model.modules())\n",
    "        for idx,idxx in enumerate(self.prunable_idx):\n",
    "            mi = m_list[idxx]\n",
    "            # replace conv\n",
    "            mask = all_mask[idx]\n",
    "            X = self.op_randX[mi][:,mask,:,:].data.cpu().numpy()\n",
    "\n",
    "            Y = None\n",
    "            if idx != len(self.prunable_idx)-1:\n",
    "                mask_output = all_mask[idx+1]\n",
    "                Y = self.op_randY[mi][:,mask_output].data.cpu().numpy()\n",
    "            else:\n",
    "                Y = self.op_randY[mi][:,:].data.cpu().numpy()\n",
    "\n",
    "            \n",
    "            from lib.utils import least_square_sklearn\n",
    "            N,c,h,w = X.shape\n",
    "            N,o = Y.shape\n",
    "            X = X.reshape((N,-1))\n",
    "            \n",
    "            W = least_square_sklearn(X,Y)\n",
    "            mp = mp_list[idxx]\n",
    "            W = W.reshape((o,c,h,w))\n",
    "            mp.weight.data.copy_(torch.from_numpy(W).cuda())\n",
    "\n",
    "            if idx != 0 :\n",
    "                j = idxx - 1 \n",
    "                while True:\n",
    "                    mj = mp_list[j]\n",
    "                    mo = m_list[j]\n",
    "                    if type(mj) == nn.BatchNorm2d:\n",
    "                        mj.weight.data.copy_(torch.from_numpy(mo.weight.data.cpu().numpy()[mask]).cuda())\n",
    "                        mj.bias.data.copy_(torch.from_numpy(mo.bias.data.cpu().numpy()[mask]).cuda())\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        j-=1\n",
    "\n",
    "            \n",
    "        for idx,idxx in enumerate(self.all_idx):\n",
    "            if idxx > self.prunable_idx[-1]:\n",
    "                mo = m_list[idxx]\n",
    "                mp = mp_list[idxx]\n",
    "                if type(mp) == nn.BatchNorm2d:\n",
    "                    mp.weight.data.copy_(torch.from_numpy(mo.weight.data.cpu().numpy()).cuda())\n",
    "                    mp.bias.data.copy_(torch.from_numpy(mo.bias.data.cpu().numpy()).cuda())\n",
    "                    mp.running_mean.data.copy_(torch.from_numpy(mo.running_mean.data.cpu().numpy()).cuda())\n",
    "                    mp.running_var.data.copy_(torch.from_numpy(mo.running_var.data.cpu().numpy()).cuda())\n",
    "                elif type(mp) == nn.Linear:\n",
    "                    mp.weight.data.copy_(torch.from_numpy(mo.weight.data.cpu().numpy()).cuda())\n",
    "                    mp.bias.data.copy_(torch.from_numpy(mo.bias.data.cpu().numpy()).cuda())\n",
    "        \n",
    "    def _collect_XY(self):\n",
    "        model = self.model\n",
    "        handler_collection = {}\n",
    "        types_collection = set()\n",
    "        # if custom_ops is None:\n",
    "        custom_ops = {}\n",
    "\n",
    "        def add_hooks(m: nn.Module):\n",
    "\n",
    "            m_type = type(m)\n",
    "\n",
    "            fn = None\n",
    "            verbose = True\n",
    "            if m_type in custom_ops:  # if defined both op maps, use custom_ops to overwrite.\n",
    "                fn = custom_ops[m_type]\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    print(\"[INFO] Customize rule %s() %s.\" % (fn.__qualname__, m_type))\n",
    "            elif m_type in register_hooks:\n",
    "                fn = register_hooks[m_type]\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    print(\"[INFO] Register %s() for %s.\" % (fn.__qualname__, m_type))\n",
    "            else:\n",
    "                if m_type not in types_collection and verbose:\n",
    "                    prRed(\"[WARN] Cannot find rule for %s. Treat it as zero Macs and zero Params.\" % m_type)\n",
    "\n",
    "\n",
    "            def collect_x_y(m,x,y):\n",
    "\n",
    "                if type(m) != nn.Conv2d:\n",
    "                    return\n",
    "                \n",
    "                x = x[0]\n",
    "                x = torch.nn.functional.pad(x,pad=(1,1,1,1),value = 0)\n",
    "                B,c,HI,WI = x.shape\n",
    "                B,n,HO,WO = y.shape\n",
    "                n,c,kh,kw = m.weight.size()\n",
    "                repair_points = self.repair_points\n",
    "\n",
    "                # 选出几个点\n",
    "                points = []\n",
    "                for i in range(repair_points):\n",
    "                    rand_x = np.random.choice(list(range(HI-kh+1)))\n",
    "                    rand_y = np.random.choice(list(range(WI-kw+1)))\n",
    "                    points.append([rand_x,rand_y])\n",
    "                \n",
    "                chosen_X = None\n",
    "                chosen_Y = None\n",
    "                for i in range(repair_points):\n",
    "                    rand_x,rand_y = points[i]\n",
    "                    if chosen_X == None:\n",
    "                        chosen_X = x.clone()[:,:,rand_x:rand_x+kh,rand_y:rand_y+kw]\n",
    "                        chosen_Y = y.clone()[:,:,rand_x,rand_y]\n",
    "                    else:\n",
    "                        chosen_X = torch.cat([chosen_X,x.clone()[:,:,rand_x:rand_x+kh,rand_y:rand_y+kw]])\n",
    "                        chosen_Y = torch.cat([chosen_Y,y.clone()[:,:,rand_x,rand_y]])\n",
    "\n",
    "                if m.input_features == None and m.output_features == None:\n",
    "                    m.input_features = x.clone()\n",
    "                    m.output_features = y.clone()\n",
    "                    m.sample_X = chosen_X\n",
    "                    m.sample_Y = chosen_Y\n",
    "\n",
    "                else:\n",
    "                    m.input_features = torch.cat([m.input_features,x.clone()],0)\n",
    "                    m.output_features = torch.cat([m.output_features,y.clone()],0)\n",
    "                    m.sample_X = torch.cat([m.sample_X,chosen_X],0)\n",
    "                    m.sample_Y = torch.cat([m.sample_Y,chosen_Y],0)\n",
    "\n",
    "                \n",
    "            if fn is not None: \n",
    "                m.register_buffer('input_features', None,persistent=False)\n",
    "                m.register_buffer('output_features', None,persistent=False)\n",
    "                m.register_buffer('sample_X', None,persistent=False)\n",
    "                m.register_buffer('sample_Y', None,persistent=False)\n",
    "                \n",
    "                handler_collection[m] = (m.register_forward_hook(collect_x_y))\n",
    "            types_collection.add(m_type)\n",
    "\n",
    "        prev_training_status = model.training\n",
    "\n",
    "        model.eval()\n",
    "        model.apply(add_hooks)\n",
    "        repair_points = self.repair_points\n",
    "        train_loader = self.train_loader\n",
    "        with torch.no_grad():\n",
    "            for i_b ,(input,target) in enumerate(train_loader):\n",
    "                if i_b == repair_points:\n",
    "                    break\n",
    "                input_var = torch.autograd.Variable(input).cuda()\n",
    "                _ = model(input_var)\n",
    "\n",
    "\n",
    "        self.op_input = {}\n",
    "        self.op_output = {}\n",
    "        self.op_randX = {}\n",
    "        self.op_randY = {}\n",
    "        for op in self.prunable_ops:\n",
    "            self.op_input[op] = op.input_features\n",
    "            self.op_output[op] = op.output_features\n",
    "            self.op_randX[op] = op.sample_X\n",
    "            self.op_randY[op] = op.sample_Y\n",
    "\n",
    "        model.train(prev_training_status)\n",
    "        for m, (xy_handler) in handler_collection.items():\n",
    "            xy_handler.remove()\n",
    "            m._buffers.pop(\"input_features\")\n",
    "            m._buffers.pop(\"output_features\")\n",
    "            m._buffers.pop(\"sample_X\")\n",
    "            m._buffers.pop(\"sample_Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "n_data_worker= 1\n",
    "data_type = 'cifar10'\n",
    "data_root = 'C:\\\\Users\\\\lenovo\\\\dataset\\\\cifar'\n",
    "repair_points = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1,bias=True),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "#maskvgg: perserve_ratio ratio is 1-d array \n",
    "class MaskVGG(nn.Module):\n",
    "    def __init__(self, vgg_name, perserve_ratio):\n",
    "        super(MaskVGG, self).__init__()\n",
    "        self.perserve_ratio = perserve_ratio\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(int(512*perserve_ratio[-1]), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "        \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        Mlayers = 0\n",
    "        for x_index, x in enumerate(cfg):\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "                Mlayers += 1\n",
    "            else:\n",
    "                x = int(x * self.perserve_ratio[x_index - Mlayers])\n",
    "                \n",
    "                if x == 0:\n",
    "                    x = 1\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1,bias=False),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "vgg = VGG('vgg16').cuda()\n",
    "sd = torch.load(r'C:\\Users\\lenovo\\Desktop\\cacp\\cacp_vgg\\checkpoints\\vgg16_cifar10.pt')\n",
    "vgg.load_state_dict(sd['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Preparing data: cifar10...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "=> Extracting information...\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "\u001b[91m [WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m [WARN] Cannot find rule for <class '__main__.VGG'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "\u001b[91m [WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m [WARN] Cannot find rule for <class '__main__.VGG'>. Treat it as zero Macs and zero Params.\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "fm = FM_reconstruct(\n",
    "vgg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [1.0]*13\n",
    "fm.compress(action)\n",
    "fm.validate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('dl': conda)",
   "language": "python",
   "name": "python37864bitdlconda025d52b019884f6b8897469d357de104"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
